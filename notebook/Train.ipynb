{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../autoencoder/\")\n",
    "from model import MoleculeVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', '5', ':', 'W', '4', '7', 's', 'I', 'O', '\\\\', '[', 'f', 'H', '9', 'b', 'r', 'K', 'n', 'd', '8', 'T', '+', 'S', 'F', 'c', '(', 'Y', 'e', 'R', 'P', 'a', 'V', 'M', 'D', 'N', '0', 'Z', 'X', 'p', 'l', '.', '2', 'E', 'G', 'y', '#', '-', '6', '1', 'A', 'g', '/', '%', ')', ']', '3', 'B', '@', 'i', 'L', 'o', 'u', '=', 'h', 'C', 't']\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "data = pandas.read_hdf(\"test\",'table')\n",
    "charset = list(np.load(\"symbols.npy\"))\n",
    "print(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import functools\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from autoencoder.utils import one_hot_array, one_hot_index\n",
    "\n",
    "smiles_column = 'structure'\n",
    "keys = data[smiles_column].map(len) < 121\n",
    "\n",
    "#length = len(keys) - 20\n",
    "#print(len(data[keys]),length)\n",
    "#length = 10\n",
    "\n",
    "#if length <= len(keys):\n",
    "#    data = data[keys].sample(n = length)\n",
    "#else:\n",
    "    \n",
    "data = data[keys]\n",
    "\n",
    "structures = data[smiles_column].map(lambda x: list(x.ljust(120)))\n",
    "\n",
    "#if args.property_column:\n",
    "#    properties = data[args.property_column][keys]\n",
    "\n",
    "#del data\n",
    "\n",
    "train_idx, test_idx = train_test_split(range(structures.shape[0]), test_size = 0.20)\n",
    "\n",
    "charset = list(functools.reduce(lambda x, y: set(y) | x, structures, set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'E', ')', '6', '%', 'C', 'O', 'D', 'K', 't', 'G', 'n', 'T', '[', '-', 'M', 'I', '/', 'N', 'Z', 'u', 'S', 'p', 'g', '(', 'B', 'Y', 'H', '0', 'i', 'y', ':', 'o', '@', '8', 'X', 'A', '2', 'e', ']', 'a', '1', 'L', 'd', ' ', '7', 'P', 'R', 'm', 'c', '\\\\', '=', 'b', 's', 'F', '3', 'l', 'V', 'r', '9', '#', '4', '+', '5']\n",
      "(1001433,)\n"
     ]
    }
   ],
   "source": [
    "print(charset)\n",
    "print (structures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "def one_hot_encoded(sub_structures):\n",
    "    return  np.array(list(\n",
    "    map(lambda row:\n",
    "        list(map(lambda x: one_hot_array(x, len(charset)),\n",
    "            one_hot_index(row, charset))),\n",
    "        sub_structures)))\n",
    "\n",
    "def generator(test=False):\n",
    "    size = batch_size\n",
    "    if test:\n",
    "        idx = test_idx\n",
    "    else:\n",
    "        idx = train_idx\n",
    "    i = 0\n",
    "    while True:\n",
    "        sample = idx[i * size:(i + 1) * size]\n",
    "        #print(structures[sample])\n",
    "        if (i + 1) * size > len(idx):\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "        X = one_hot_encoded(structures[sample])\n",
    "        yield (X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#one_hot_encoded(structures[[0,1]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 120, 64)\n"
     ]
    }
   ],
   "source": [
    "train = generator()\n",
    "for i in train:\n",
    "    print(i[0].shape)\n",
    "    break\n",
    "test = generator(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from model import MoleculeVAE\n",
    "from keras.callbacks2 import ModelCheckpoint, ReduceLROnPlateau\n",
    "model = MoleculeVAE()\n",
    "mfile =\"new.h5\"\n",
    "latent_dim = 292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1335"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(train_idx) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(mfile):\n",
    "    model.load(charset, mfile, latent_rep_size = latent_dim)\n",
    "else:\n",
    "    model.create(charset, latent_rep_size = latent_dim)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = mfile,\n",
    "                               verbose = 1,\n",
    "                               save_best_only = True,\n",
    "                              save_weights_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              min_lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "    50/801140 [..............................] - ETA: 1533931s - loss: 3.9808 - acc: 0.6393"
     ]
    }
   ],
   "source": [
    "model.autoencoder.fit_generator(train,\n",
    "                                samples_per_epoch = int(len(train_idx) / batch_size) * batch_size,\n",
    "                                nb_epoch=20,\n",
    "                                validation_data = test,\n",
    "                                nb_val_samples = 2,\n",
    "                                callbacks = [checkpointer, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
